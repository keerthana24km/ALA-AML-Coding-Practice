{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Tutorial\n",
    "\n",
    "1. Mandatory pre-requisite reading: Chapter 4 from \"Python for Data Science Handbook\" by Jake Vandasplas\n",
    "2. Numpy Documentation: https://numpy.org/doc/stable/\n",
    "2. User Guide & API Reference\n",
    "3. Watch out for the version of numpy you are using and the documentation you are referring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Background on Python data types\n",
    "\n",
    "##### 1.1 Simple data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python numbers are inferred, Numpy numbers can be inferred or specified \n",
    "counter = 0\n",
    "\n",
    "# We can provide PEP484 type hints.\n",
    "# NOTE: This is for human readability only\n",
    "# Python wont complain even if you put a invalid type hint\n",
    "counter: int = 0\n",
    "\n",
    "# Python is implemented in C\n",
    "# A Data Type in Python is a data structure in C\n",
    "\n",
    "# We can find the memory location of a python variable like this\n",
    "id(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Memory address of counter variable is {id(counter)}\") \n",
    "\n",
    "# what is the size of int datatype in bytes?\n",
    "import sys\n",
    "sys.getsizeof(counter) #whopping 24 (28) bytes (not bits) to store a number !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Collection data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python list can hold mixed type of data \n",
    "# Data may not be stored sequentially stored at different locations \n",
    "l = [1,2,3,4,5,'abc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us do something destructive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list()\n",
    "a.append(\"Hello\")\n",
    "type(a)\n",
    "\n",
    "list = \"Hello\"\n",
    "b = list() #Can you tell why this line gives errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do you want to do something even more destructive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 10\n",
    "y = str(10)\n",
    "print(y)\n",
    "\n",
    "str = \"hello world\"\n",
    "y = str(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moral of the Story\n",
    "\n",
    "1. Do not name your variable/function with python functions or datatype names\n",
    "2. Python will not complain if you do so.\n",
    "3. But from that point onwards, your python will be completely messed. \n",
    "4. Every invocation may get redirected to the re-definition\n",
    "\n",
    "5. Also do not reuse variable and function names in your own application space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the length of a collection data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3,4,5,'abc']\n",
    "\n",
    "print(len(l)) #len() function is implemented by many python types and data structures\n",
    "\n",
    "# Check the memory address of adjacent items in list. Are they adjacent in memory?\n",
    "print(id(l[0]))\n",
    "print(id(l[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second verification if list items are contiguous \n",
    "# Lets find the size of each item \n",
    "# Then see if the above memory address for l[0] and l[1] are contiguous \n",
    "sys.getsizeof(l[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Python dense array\n",
    "\n",
    "1. Gives efficient storage compared to List\n",
    "2. But no efficient operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "\n",
    "list2 = [1,2,3,4,5] # A list with same data type\n",
    "\n",
    "darray = array.array(\"i\", list2) # here i stands for integer data type\n",
    "darray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(darray[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://www.softwaretestinghelp.com/wp-content/qa/uploads/2021/04/fig2_syntax.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Starting with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__ #Check the numpy version for sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 numpy data types\n",
    "\n",
    "1. numpy maintains a separate set of data types other than python\n",
    "2. There are around 24 data types in all (in latest version of numpy) - See Jake Vanderplas 4th chapter as you read later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"https://numpy.org/doc/stable/_images/dtype-hierarchy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 numpy creation with inferred data type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,5,-8]) #Data type of individual entries is inferred automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(a)) # print the data type of the numpy array\n",
    "\n",
    "print(type(a[0])) # print the data type of first element numpy array\n",
    "\n",
    "# Alternate way of getting the data type of entries of numpy array\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1.0, 2.0, 3.0]) #data type is inffered to be float due to the decimal point\n",
    "b.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Cautionary Digression: Printable representation are never indication of data type  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of print function on a numpy array is very misleading\n",
    "# Output makes you feel as if it is a list, but it is not\n",
    "print(a)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do a print and repr on a list to compare\n",
    "int_list = [ 1,  2,  3,  5, -8]\n",
    "\n",
    "print(int_list)\n",
    "int_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4 Explicitly specifying data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of specified type\n",
    "b = np.array([1, 2, 3], dtype='f')\n",
    "\n",
    "print(f\"b.dtype={b.dtype}\") #This will show float32\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,5,-8])\n",
    "a.astype(np.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the int array into float array\n",
    "a.astype(float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what happened here. Why is numpy array a not showing as float anymore \n",
    "# hint: astype() operation is not a in place modification\n",
    "a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct way \n",
    "new_arr = a.astype(float)\n",
    "new_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5 Why so much stress on data type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        \"intfield1\":[4,5,6,10,12],\n",
    "        \"intfield2\":[100,101,102,103,104],\n",
    "        \"floatfield1\":[4.0,5.0,6,10,12],\n",
    "        \"floatfield2\":[9.0,10.0,11,12,13],\n",
    "        \"intfield3\":[95,96,97,98,98]\n",
    "        })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "        (4,100,4.0,9.0,95),(5,101,5.0,10.0,96), (6,102,6.0,11,97), \n",
    "        (10,103,10.0,12,98), (12,104,12.0,13,98)],\n",
    "    dtype=[(\"intfield1\", \"i1\"), (\"intfield2\", \"i1\"), (\"floatfield1\", 'f2'), \n",
    "            (\"floatfield2\", 'f2'),(\"intfield3\", \"i1\")])\n",
    "df = pd.DataFrame(data, columns=[\"intfield1\", \"intfield2\", \"floatfield1\", \"floatfield2\", \"intfield3\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage=\"deep\") #50% savings in data compared to inferred type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Numpy Vector operations\n",
    "\n",
    "##### 3.1 Create a column vector and calculate transpose\n",
    "\n",
    "There is confusion about shapes for column and row vectors if not done right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,5,-8])\n",
    "print(a.shape)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_transpose = a.T  # This transpose never works. why?\n",
    "print(a_transpose.shape)\n",
    "a_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,5,-8]).reshape(-1,1)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_transpose = a.T  # This transpose works. why?\n",
    "print(a_transpose.shape)\n",
    "a_transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Creating a 2D numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Display the array\n",
    "print(a)\n",
    "\n",
    "# Attributes of the array\n",
    "# Shape of the array\n",
    "print(a.shape)\n",
    "\n",
    "# Data type of array elements\n",
    "print(a.dtype)\n",
    "\n",
    "# What type of object is the variable 'a'?\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten a 2D array\n",
    "# Question: Where will this be possibly used?\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "a_flat = a.flatten()\n",
    "print(a_flat.shape)\n",
    "a_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten a 2D array\n",
    "# Where will this be possibly used?\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "a_colvector = a.reshape(?,?) #Fill this\n",
    "print(a_colvector.shape)\n",
    "a_colvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a_colvector.reshape(3,2)) # 3x2 matrix\n",
    "print(a_colvector.reshape(2,3)) # 2x3 matrix\n",
    "print(a_colvector.reshape(1,6)) #row vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 1D array indexing in numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(a[0])\n",
    "print(a[1])\n",
    "\n",
    "print(a[-1]) # first element from the tail of the array\n",
    "print(a[-2]) # second element from the tail of the array\n",
    "\n",
    "#print(a[5]) # throws an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4 2D array indexing in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "print(a)\n",
    "print('----')\n",
    "print(a[0, 0])\n",
    "print(a[-1, 0])\n",
    "print(a[0, -1])\n",
    "print(a[-1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5 Digression - for looping in python on list\n",
    "\n",
    "1. Direct looping over list\n",
    "2. Looping with range\n",
    "3. Looping with enumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct list iteration\n",
    "lst = [1,2,3,4,5,'abc']\n",
    "\n",
    "for i in lst:\n",
    "    print(i, end = \" \")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"length = {len(lst)}\")\n",
    "\n",
    "#we can access "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does range do\n",
    "# iterates from starting point to one less than specifed value\n",
    "# C equivalent is for(i = 0; i< 3; i++)\n",
    "for i in range(3):\n",
    "    print(i, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [1,2,3,4,5,'abc']\n",
    "\n",
    "# Using range without a starting point\n",
    "# uses 0 as the starting point\n",
    "for i in range(len(lst)):\n",
    "    print(lst[i], end=\" \")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Using range with a starting point\n",
    "for i in range(3, len(lst)):\n",
    "    print(lst[i], end=\" \")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Using range with a starting, ending point and step size\n",
    "for i in range(2, len(lst), 2):\n",
    "    print(lst[i], end=\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [1,2,3,4,5,'abc']\n",
    "for x in enumerate(lst):\n",
    "    print(x, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using enumerate gives access to the index variable\n",
    "for i, item in enumerate(lst): #Format for unpacking a tuple format\n",
    "    print(lst[i], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using zip function to iterate two related sequences\n",
    "# Usage: zip(iterator1, iterator2, iterator3 ...)\n",
    "\n",
    "people = [\"Vishwas\", \"Akarsh\", \"Mohit\", \"Aditya\", \"Rakshit\"]\n",
    "salary_in_lakhs = [19, 9.5, 10, 12, 14]\n",
    "\n",
    "for person, salary in zip(people, salary_in_lakhs):\n",
    "    print(f\"{person} {salary} lakhs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5 python list slicing\n",
    "\n",
    "1. Can be done for anything iterable - including strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing a list \n",
    "lst = [1,2,3,4,5,'abc']\n",
    "lst_first_3 = lst[0:3]\n",
    "lst_first_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing a list with steps\n",
    "lst = [1,2,3,4,5,'abc']\n",
    "lst_jump2 = lst[0::2]\n",
    "lst_jump2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing and skip last\n",
    "lst = [1,2,3,4,5,'abc']\n",
    "lst_skiplast = lst[0:-1]\n",
    "lst_skiplast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reversing\n",
    "lst = [1,2,3,4,5,'abc']\n",
    "lst_reverse = lst[::-1]\n",
    "lst_reverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.6 1D array slicing in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(a)\n",
    "\n",
    "print('-----')\n",
    "\n",
    "# Get all elements of the array\n",
    "print(a[:])\n",
    "\n",
    "# Specify a slice with start and end indices\n",
    "print(a[:3])\n",
    "print(a[1:3])\n",
    "print(a[2:])\n",
    "print(a[:-1]) # skips the tail element of the array\n",
    "\n",
    "print(a[-3:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[0:-1:2]) # start from first element, skip the last element, jump by 2\n",
    "print(a[0::2]) # start from first element, include the last element, jump by 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.7 Slicing 2D array (2D Data Matrix) as features and samples\n",
    "\n",
    "Patient dataset corresponding to 4 patients and 3 features:\n",
    "\n",
    "![Patient dataset](https://bl3302files.storage.live.com/y4mlspYO-L_1kEGpBOCUilkrcj3evQtgjGXDt6v2NgJwtsJf2OZVnwRnUht7CmW_wk8VMlMyGfhDqgRubB3pLHXAOe3r-pQ5wtYUuOqR_gsZzHWCqE2IEbhBjUZob5suLplmONyMsAjr1twDPK7eGODrKyav1dP1aX3lWx1YV0hiLvuTEZ7-GujIypTMkaSV2or?width=256&height=153&cropmode=none)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectors from the data matrix**\n",
    "\n",
    "![Patient dataset](https://bl3302files.storage.live.com/y4mTMCQdiTnIFj1IALg09CRz7pPWl0g4HpigAPbwyMmF0QNliGAgK3aEsBESo0BNFCy-0-kR6pllskO1DPVt2-76bYsQaACRWhkOebqJ545BbtWcGr1CJG72BZJPrYbQDWNAC0h1EHhpewBlORT_xtahEu-bite73OVi-4CzGeQf6GDw11H6kn72VocdC2bLAsJ?width=256&height=167&cropmode=none)\n",
    "\n",
    "1st feature vector (heart rate) for all patients:\n",
    "$$x_1 = \\begin{bmatrix}76\\\\74\\\\72\\\\78\\end{bmatrix}$$\n",
    "\n",
    "1st patient vector for all features:\n",
    "$$x^{(1)} = \\begin{bmatrix}76\\\\126\\\\38\\end{bmatrix}$$\n",
    "\n",
    "Therefore Patient Matrix can be written as \n",
    "$$ \\begin{bmatrix} {x^{(1)}}^T \\\\ {x^{(2)}}^T \\\\  {x^{(3)}}^T \\\\  {x^{(4)}}^T \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create patient data matrix\n",
    "df_patient = pd.DataFrame({'HR' : [76, 74, 72, 78],\n",
    "                           'BP' : [126, 120, 118, 136],\n",
    "                           'Temp': [38, 38, 37.5, 37]})\n",
    "\n",
    "df_patient.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_patient.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_patient)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the features\n",
    "print(X[:, 0]) # first feature vector\n",
    "print(X[:, 0].shape)\n",
    "\n",
    "# Slice the samples\n",
    "print(X[1, :]) # second sample vector with label\n",
    "print(X[1, :-1]) # second sample vector without its label\n",
    "print(X[1, :].shape)\n",
    "\n",
    "# Slice the output labels\n",
    "print(X[:2, -1])# output label for samples 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.8 Load a real dataset and apply slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use a publicly available CSV format dataset to load directly in Pandas\n",
    "df_pima = pd.read_csv(\"https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv\")\n",
    "df_pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the above approach didnt work, then download the file from here\n",
    "# https://github.com/jbrownlee/Datasets/blob/master/pima-indians-diabetes.data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = df_pima.to_numpy()\n",
    "print(Xy.shape)\n",
    "Xy[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the combined dataset containing predictor variables and target variable\n",
    "# into predictor only and target only\n",
    "\n",
    "X = Xy[:,:-1] # Extracting predictors/features\n",
    "y = Xy[:,-1] # Right way to extract target variable (unfortunately)\n",
    "y_alt = Xy[:,-1:] #Can you recall how does this method extract target?\n",
    "\n",
    "print(X.shape) #Check the shape should be one less than Xy combined\n",
    "print(y.shape)\n",
    "print(y_alt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Lets do some visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is this important?\n",
    "from yellowbrick.target import ClassBalance\n",
    "\n",
    "visualizer = ClassBalance(labels=[1, 0])\n",
    "visualizer.fit(y) # Fit the data to the visualizer\n",
    "visualizer.show() # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Apply Logistic Regression on the diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(X,y) #Do you recall this fit method as the training phase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will restrict to these predictors \"Pregnancies\", \"Glucose\",\"BloodPressure\"\n",
    "# These are first three columns in dataset. Their indexes are 0,1,2\n",
    "#Do you recall this fit method as the training phase?\n",
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(X[:,0:3],y_alt) # This fails with a self explanatory error. Fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict phase\n",
    "## Defining the y_pred variable for the predicting values. \n",
    "y_pred=lr_classifier.predict(X) #Can you think why this is failing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lr_classifier.predict(X[:,0:3]) # y had actual values, y_pred has predicted values\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y, y_pred, labels=lr_classifier.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lr_classifier.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "visualizer = ROCAUC(lr_classifier, classes=lr_classifier.classes_)\n",
    "visualizer.fit(X[:,0:3], y)        \n",
    "visualizer.score(X[:,0:3], y)        \n",
    "visualizer.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import FeatureImportances\n",
    "\n",
    "viz = FeatureImportances(lr_classifier)\n",
    "viz.fit(X[:,0:3], y)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework:\n",
    "1. Given that the feature importance are as shown in the plot generated in the above cell, use Pregnancies alone and do a Logistic regression. Compare the metrics for what has been done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are not done yet. What is coming?\n",
    "\n",
    "The following are tentative topics for the next 2 labs.\n",
    "Some like pipeline will be moved out after implementation of 1 or 2 algorithms to emphasise the need for pipelines.\n",
    "\n",
    "1. We ran the above fit-predict on the same set of data X. We need test train split\n",
    "2. How to shuffle data randomly\n",
    "3. We have not seen how multiple numpy arrays can be stacked horizontally or vertically\n",
    "4. Tensors - 3D\n",
    "5. Reduction operations on different axis\n",
    "6. sort, argsort\n",
    "7. scipy\n",
    "8. Numpy broadcasting\n",
    "9. Ufuncs, \n",
    "10. vectorization. why is it very important\n",
    "11. Using datasets built into Pandas\n",
    "12. Some more frequently used Pandas operations\n",
    "13. Very basic plotting directly from Pandas, matplotlib, and seaborn\n",
    "14. use of meshgrid in plotting, subplots\n",
    "15. Exploratory Data Analysis (Template will be provided) - Stats, Transformations, Imputations, Feature Selections, Extractions, Engin\n",
    "16. Extensive sklearn pipeline construction, familiarizing with sklearn class inheritance \n",
    "17. Tensorflow basic operations (outside of Deep learning)\n",
    "18. Interpreting accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quickstart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
